{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232a1e32-4fb9-49e5-8307-9e11f12a3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Load the saved model\n",
    "imported = tf.saved_model.load(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7877733d-e26e-4eef-9596-55ba74a5386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
      "array([[ 26.047459 , -29.991695 ,   1.4758577, -15.930263 ]],\n",
      "      dtype=float32)>, 'class_ids': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0], dtype=int64)>, 'class_names': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Sound_Drum'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "test1 = tf.io.read_file(\"New_Test/Sound_Drum/100bpm-808-like-drum-loop-74838.wav\")\n",
    "waveform1, _ = tf.audio.decode_wav(test1, desired_channels=1, desired_samples=1600000)\n",
    "waveform1 = tf.squeeze(waveform1, axis=-1)\n",
    "# Add batch dimension\n",
    "output1 = imported(tf.expand_dims(waveform1, 0)) \n",
    "\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee249fe9-9b1c-4e2b-9352-7cc048ac181b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a179bd2e-0ecb-4d36-8f84-633f64517c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 2.030481 , -7.936515 ,  2.0641294,  2.4583647]], dtype=float32)>, 'class_ids': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([3], dtype=int64)>, 'class_names': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Sound_Violin'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "test2 = tf.io.read_file(\"New_Test/Sound_Violin/Sad-Violin-H-www.fesliyanstudios.com.wav\")\n",
    "waveform2, _ = tf.audio.decode_wav(test2, desired_channels=1, desired_samples=1600000)\n",
    "waveform2 = tf.squeeze(waveform2, axis=-1)\n",
    "# Add batch dimension\n",
    "output2 = imported(tf.expand_dims(waveform2, 0))  \n",
    "\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216e19a6-d874-4f23-8546-c32cd6370479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[-2.912892 , 11.377988 , -5.1343093, -8.177461 ]], dtype=float32)>, 'class_ids': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1], dtype=int64)>, 'class_names': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Sound_Guitar'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "test3 = tf.io.read_file(\"New_Test/Sound_Guiatr/rock_2_100BPM.wav\")\n",
    "waveform3, _ = tf.audio.decode_wav(test3, desired_channels=1, desired_samples=1600000)\n",
    "waveform3 = tf.squeeze(waveform3, axis=-1)\n",
    "# Add batch dimension\n",
    "output3 = imported(tf.expand_dims(waveform3, 0))  \n",
    "\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0cac82-0d90-44ea-a57f-198f26d50a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
      "array([[-1.3494622 , -0.28962806,  1.6850353 , -1.7057853 ]],\n",
      "      dtype=float32)>, 'class_ids': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2], dtype=int64)>, 'class_names': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Sound_Piano'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "test4 = tf.io.read_file(\"New_Test/Sound_Piano/ROOM-room8-MUS-chords.wav\")\n",
    "waveform4, _ = tf.audio.decode_wav(test4, desired_channels=1, desired_samples=1600000)\n",
    "waveform4 = tf.squeeze(waveform4, axis=-1)\n",
    "# Add batch dimension\n",
    "output4 = imported(tf.expand_dims(waveform4, 0)) \n",
    "\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39ff19-4a60-4155-bbd3-cf8742557e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
